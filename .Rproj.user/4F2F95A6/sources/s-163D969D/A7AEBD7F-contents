---
title: "Modulo VII_EJERCICIOS_Jaime_Salazar_930"
author: "Jaime Salazar"
date: "11/12/2020"
output: 
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    theme: united #darkly
    fig_width: 7
    fig_height: 6
    fig_caption: true
---

### Ej 1. 

Con la base de datos encuesta.dat:


#### 1.1. Haz un análisis que ponga a prueba si la fluidez verbal en español puede predecir la fluidez verbal en ingles:

##### Respuesta

Cargue de datos y librerias.

```{r message = FALSE}

library(tidyverse)
library(psych)
library(lmtest)
# encuesta_org <- read.table(file.choose(), header=T, sep="\t",dec=',')
encuesta_org <- read.table("encuesta.dat", header=T, sep="\t",dec=',')
# Se realiza copia del original:
dat <- encuesta_org;glimpse(dat[1:10])
```

Definición de variables:

* **x: Var Ind : fluidez verbal en español FV~e~** (FluidezVerbalEspanol)
* **y: Var Dep : fluidez verbal en ingles FV~i~**(FluidezVerbalIngles)

Aplicación de modelo lineal:

```{r message = FALSE}
m <- lm(dat$FluidezVerbalIngles ~ dat$FluidezVerbalEspanol)
summary(m)
```

#### 1.2. Interpreta y representa los resultados

```{r message = FALSE}
ggplot(dat)+
  geom_jitter(aes(FluidezVerbalEspanol,FluidezVerbalIngles))+
  geom_smooth(aes(FluidezVerbalEspanol,FluidezVerbalIngles),method = "lm")+
  theme_classic()+
  labs(x = "FV Espanol", y = "FV Ingles")
```


De esta forma se tiene:

$$y(x) = B_o + B_1 * X$$
donde:

 * B~o~ = 1.0969 
 
 * B~1~ = 0.2893
 
$$FV_i (FV_e) = 1.0969 + 0.2893 * FV_e$$
Es decir, el modelo resultante sugiere que por cada punto en **FV~e~** se aumenta
**0.2893** puntos de **FV~i~** con una base de: **FV~i~ (0) = 1.096**.

Adicionalmente, el **p.value** del para el modelo con respecto a *$**FV~e~* es **0.000245** por lo que se rechaza **H~o~** (B~1~ = 0). por los que se puede concluir que B~1~, la pendiente de nuestro modelo, es significativamente diferente de **0** 

#### 1.3. Haz el pronostico de la fluidez verbal en ingles de una persona con fluidez verbal en español = 12

Se generará función:

```{r}
FV_Ing <- function (FV_Esp) {
  return(as.numeric(m$coefficients[1] + m$coefficients[2] * FV_Esp))
#  return(1.0969 + 0.2893 * FV_Esp)
}

## Respuesta 
FV_Ing(12)
```

#### 1.4. Comprueba los supuestos

#### Linealidad


Se comprobara mediante test de correlación y grafica:
```{r}
#Test corelación
cor.test(dat$FluidezVerbalIngles, dat$FluidezVerbalEspanol)
## R = 0.3968231 


#Grafica
ggplot(dat)+
  geom_jitter(aes(FluidezVerbalEspanol,FluidezVerbalIngles))+
  geom_smooth(aes(FluidezVerbalEspanol,FluidezVerbalIngles),method = "lm")+
  theme_classic()+
  labs(x = "FV Espanol", y = "FV Ingles")


```

**R = 0.3968231**. Entonces, tanto el grafico como R nos indican que el modelo lineal no se ajusta de buena forma a nuestros datos, relación debil R < 0.8 (supuesto).

#### Normalidad

```{r results = 'hide'}
resi <- data.frame(m$residuals)
```
```{r message = FALSE}
# Gráfico
ggplot(resi, aes(m.residuals))+
  geom_density(fill="#331bab")+
  theme_classic()+ stat_function(fun = dnorm)

qqnorm(m$residuals, main="Q-Q plot de los residuos del modelo");
qqline(m$residuals,distribution = qnorm)

# Test de normalidad
ks.test(resi,"pnorm")
```

Dado que **p.value= < 6.571e-05 < 0.05 **  Se rechaza H~o~.

Tanto graficamente, como por test de normalidad KS, se verifíca que no se cumple el supuesto de normalidad.



#### Homocedasticidad

```{r}
data.frame(pro=m$fitted.values,resi=m$residuals) %>% 
  ggplot(aes(pro,resi))+
  geom_jitter()+theme_classic()
```

Dispersion de los pronosticos en base a los residuos la nube de puntos no permite aclarar si estan distribuida homogeneamente en torno al valor cero del eje vertical.

#### Independencia
```{r}
plot(dat$FluidezVerbalIngles,resid(m))
dwtest(m)
```

los residuos no estan aleatoriamente repartidos. 
Sin embargo, Durbin-Watson sugiere que si son  (debe estar entre **1.5-2.5**, en ejemplo = *1.79*).